操作系统内核对于I/O只有两种方式：阻塞和非阻塞

操作系统将所有的输入输出设备都抽象为文件，内核在进行文件I/O操作时，通过文件描述符进行管理。

阻塞I/O：应用程序需要等待I/O操作完成才返回结果
非阻塞I/O：不带数据直接返回，应用程序需要重复调用I/O操作来确认是否完成，即轮询

【轮询技术】
	read：最原始、性能最低的方式。通过重复调用来检查I/O的状态来完成完整数据的读取    【read调用会立即返回】
	select：通过对文件描述符上的事件状态来进行判断。								 
			它采用一个1024长度的数组来存储状态，所以最多可以同时检查1024个文件描述符
	poll：相比select，poll采用链表的方式来避免数组长度的限制，性能相比select要高，但是文件描述符较多时性能还是很低。	 
	epoll：linux下效率最高的I/O事件通知机制
			在进入轮询的时候如果没有检测到I/O事件，将会进行休眠，直到事件将它唤醒。不需要遍历查询
	kqueue：类似epoll。仅在FreeBSD系统下存在。

	【select、poll都是在遍历文件描述符，如果是数据读取完成的状态，则再次发起一个read操作读取数据】
	【epoll是真正的通知机制，在等待期间将休眠，收到通知后再次发起一个read操作读取数据】
	
异步I/O：AIO。通过信号或回调来传递数据，不需要主动遍历轮询结果状态，也不需要休眠。
		 原生的AIO只有linux支持，且无法利用系统缓存。	
		 
		 应用层实现：
			让部分线程进行阻塞或非阻塞I/O加轮询技术来完成数据获取，让另一个线程来进行计算处理，通过线程之间的通信将I/O得到的数据进行传递。
			一些库：
			 glibc：线程池模拟异步I/O，不推荐
			 libeio：线程池与阻塞I/O模拟异步I/O 
			 IOCP：windows下采用IOCP实现异步I/O 
			 
			 
Node的异步I/O
	
	事件循环
		进程启动时，Node会创建一个无限循环，每执行一次循环体的过程叫Tick。
		每个Tick的过程就是查看是否有事件待处理，如果有就取出事件和相关的回调函数并执行回调函数，然后进入下个循环。
		如果不再有事件就退出进程
		
		事件循环是典型的生产者-消费者模型
		【事件存放在队列中，事件就是请求对象】
		
	观察者
		每个事件循环中有一个或多个观察者，判断是否有事件要处理的过程就是向观察者询问是否有要处理的事件。
		事件主要来源于网络请求 文件I/O，他们是事件的生产者， 每个事件都有对应的观察者。
		
	请求对象
		Node提供了libuv作为抽象封装层，屏蔽不同平台的异步I/O模型的差异。
		fs.open()调用C++核心模块，然后调用C++内建模块，然后通过libuv进行系统调用
		FSReqWrap封装了要调用的方法和参数以及回调函数
		请求对象会被推入线程池中等待执行，此时异步调用会立即返回
		
	I/O线程池
		js是单线程的，I/O操作利用线程池可以并行执行，不管I/O是不是阻塞，都不会影响js线程的执行。
		Node其实是多线程的。
		线程池中的I/O操作完成之后，会通知请求对象。
		
		
Node中的非I/O的异步API
	定时器
		不精确，会使用红黑树而不是线程池
		setTimeout		单次执行任务
		setInterval		多次执行任务
		
	process.nextTick()
		将回调函数放入队列中，在下一轮的Tick时取出执行
		setTimeout(callback, 0) 同理，但是浪费性能，使用nextTick性能高，因为是直接放入回调函数，而不需要创建事件对象、遍历红黑树等操作
		
	setImmediate()
		与nextTick类似，回调函数存放在链表中，但是nextTick中的回调函数的执行优先
		process.nextTick()属于idle观察者
		setImmediate()属于check观察者
		
		每一轮的循环检查中，idle观察者先于I/O观察者，I/O观察者先于check观察者
		
		process.nextTick()每轮会将数组(队列)中的所有回调函数全部执行
		setImmediate()每轮只执行链表中的一个回调函数
		
利用Node构建高性能服务器		
		